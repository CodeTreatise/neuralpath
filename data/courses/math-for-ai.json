{
  "id": "math-for-ai",
  "title": "Mathematics for AI",
  "icon": "ðŸ§®",
  "description": "Master the essential mathematical foundations needed for machine learning and deep learning.",
  "level": "beginner",
  "duration": "6 weeks",
  "totalLessons": 22,
  "prerequisites": [
    "Basic arithmetic (add, subtract, multiply, divide)",
    "Understanding of variables (like x and y in equations)",
    "No calculus required - we'll teach what you need!"
  ],
  "whatYouNeed": [
    "Calculator or any spreadsheet app",
    "Python 3.8+ (for code examples)",
    "No advanced math background - we start from scratch!",
    "Curiosity about how AI works under the hood"
  ],
  "outcomes": [
    "Understand vectors, matrices, and linear transformations",
    "Apply SVD and understand dimensionality reduction",
    "Apply calculus concepts to optimization problems",
    "Work with probability distributions and Bayes' theorem",
    "Understand information theory and cross-entropy loss",
    "Implement gradient descent from scratch",
    "Recognize numerical stability issues in practice"
  ],
  "validationSources": [
    {
      "source": "IBM Technology",
      "topics": ["Neural Networks", "Backpropagation", "Gradient Descent", "Vector Embeddings"],
      "urls": [
        "https://www.ibm.com/topics/neural-networks",
        "https://www.ibm.com/topics/backpropagation",
        "https://www.ibm.com/topics/gradient-descent",
        "https://www.ibm.com/topics/vector-embedding"
      ],
      "verified": true,
      "date": "2025-01-26"
    }
  ],
  "keyThinkers": [
    {
      "name": "Carl Friedrich Gauss",
      "contribution": "Gaussian elimination, normal distribution - foundational for linear systems and statistics",
      "era": "1777-1855"
    },
    {
      "name": "Isaac Newton & Gottfried Leibniz",
      "contribution": "Co-inventors of calculus - the mathematics of change that underlies all optimization",
      "era": "1680s"
    },
    {
      "name": "Leonhard Euler",
      "contribution": "Euler's number (e), contributions to notation and analysis fundamental to calculus",
      "era": "1707-1783"
    },
    {
      "name": "Thomas Bayes & Pierre-Simon Laplace",
      "contribution": "Bayesian probability - reasoning under uncertainty central to ML",
      "era": "1700s"
    },
    {
      "name": "Claude Shannon",
      "contribution": "Information theory, entropy - foundation of cross-entropy loss and compression",
      "era": "1916-2001"
    },
    {
      "name": "Augustin-Louis Cauchy",
      "contribution": "First formal description of gradient descent (1847) - the core of neural network training",
      "era": "1789-1857"
    }
  ],
  "modules": [
    {
      "id": "getting-started",
      "title": "Why Math for AI?",
      "description": "Understand what math you actually need and how it connects to AI",
      "lessons": [
        {
          "id": "intro",
          "title": "Math for AI: What You Actually Need",
          "type": "lesson",
          "duration": "15 min",
          "content": [
            {
              "type": "text",
              "content": "## Don't Panic! ðŸŽ¯\n\nIf math scared you in school, here's the good news: **you don't need to be a mathematician to do AI.**\n\nYou need to understand:\n1. **What** the math is doing (conceptually)\n2. **Why** it's used in AI\n3. **How** to use it in code (computers do the hard calculations!)\n\nYou do NOT need to:\n- Prove theorems\n- Do calculations by hand\n- Remember every formula"
            },
            {
              "type": "text",
              "content": "## The 4 Math Topics for AI\n\n| Topic | What It Is | Why AI Uses It |\n|-------|-----------|---------------|\n| **Linear Algebra** | Working with lists of numbers | Data comes as lists! |\n| **Calculus** | How things change | Finding the best model settings |\n| **Probability** | Dealing with uncertainty | Predictions aren't 100% certain |\n| **Optimization** | Finding the best solution | Training = finding best weights |\n\nThat's it! This course covers all four in a practical, code-first way."
            },
            {
              "type": "text",
              "content": "## Key Terms We'll Use\n\nBefore we dive in, let's define terms you'll see everywhere:\n\n- **Scalar**: Just a single number (like 5, 3.14, or -2)\n- **Vector**: A list of numbers [1, 2, 3]\n- **Matrix**: A grid of numbers (like a spreadsheet)\n- **Function**: Takes input, gives output (like a recipe)\n- **Derivative**: How fast something changes\n- **Gradient**: Which direction is 'uphill'\n\nDon't memorize these - they'll become natural as we use them!"
            },
            {
              "type": "text",
              "content": "## Common Beginner Questions\n\n**Q: Do I need to be good at math?**\nA: No! If you can follow a recipe, you can learn this. Code handles the calculations.\n\n**Q: What if I don't understand something?**\nA: That's normal! Read the concept, look at the code, run it yourself. Understanding comes from doing.\n\n**Q: Will there be formulas?**\nA: Yes, but we always explain in plain English first. Formulas are just precise notation.\n\n**Q: Should I memorize formulas?**\nA: No. Understand what they do. You can always look them up."
            },
            {
              "type": "code",
              "language": "python",
              "title": "Your First AI Math - It's Just Lists!",
              "code": "# AI math is mostly working with lists of numbers!\n\n# A person's data (age, income in thousands, credit score)\nperson = [25, 50, 720]\n\n# This list IS a vector in math terms!\n# AI models process millions of these\n\n# Multiple people = a grid (matrix)\npeople = [\n    [25, 50, 720],\n    [35, 80, 680],\n    [45, 120, 750]\n]\n\n# That's a 3x3 matrix - 3 people, 3 features each\n# See? Math isn't scary when it's just data!\n\nprint(f\"Person 1 age: {people[0][0]}\")\nprint(f\"Person 2 income: {people[1][1]}k\")\nprint(f\"Total people: {len(people)}\")"
            }
          ]
        }
      ]
    },
    {
      "id": "linear-algebra",
      "title": "Linear Algebra Essentials",
      "description": "Vectors, matrices, and transformations - the language of ML",
      "lessons": [
        {
          "id": "vectors",
          "title": "Vectors and Vector Operations",
          "type": "lesson",
          "duration": "25 min",
          "authorCredits": {
            "keyContributors": ["Hermann Grassmann"],
            "historicalNote": "Hermann Grassmann developed the modern concept of vector spaces in the 1840s. His work was ahead of its time and forms the foundation of linear algebra used in all ML systems today."
          },
          "content": [
            {
              "type": "text",
              "content": "## Tensors: The Family of Data Structures\n\n| Type | Dimensions | Example | In ML |\n|------|-----------|---------|-------|\n| **Scalar** | 0D | `5` | Single value (loss, learning rate) |\n| **Vector** | 1D | `[1, 2, 3]` | Feature list, word embedding |\n| **Matrix** | 2D | `[[1,2], [3,4]]` | Batch of samples, weight matrix |\n| **Tensor** | 3D+ | `[[[...]]]` | Images (HÃ—WÃ—C), video batches |\n\nIn code, we use the term 'tensor' for any of these (PyTorch, TensorFlow)."
            },
            {
              "type": "text",
              "content": "## What is a Vector? (Plain English First!)\n\n**A vector is just a list of numbers.** That's it!\n\n```\n[1, 2, 3] â† This is a vector\n[age, height, weight] â† So is this\n```\n\nIn math notation, we write it vertically:\n$$\\vec{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}$$\n\nBut in code, it's just a list: `[v1, v2, v3, ...]`\n\n**Dimensionality:** A vector with 3 numbers is a 3-dimensional vector. Word embeddings often use 300-768 dimensions!"
            },
            {
              "type": "text",
              "content": "## Why Vectors in AI?\n\nEverything in AI is converted to vectors:\n\n| Real World | As a Vector |\n|------------|-------------|\n| A photo | [pixel1, pixel2, ... pixel1000000] |\n| A word | [0.2, -0.5, 0.8, ... 300 numbers] |\n| A person | [age, income, credit_score] |\n| A song | [tempo, loudness, energy, ...] |\n\nAI models take vectors in, do math, output vectors."
            },
            {
              "type": "text",
              "content": "## Vector Operations\n\n### Addition (combine vectors)\nAdd matching positions:\n```\n[1, 2, 3] + [4, 5, 6] = [5, 7, 9]\n```\n\n### Scalar Multiplication (scale a vector)\nMultiply every number:\n```\n2 Ã— [1, 2, 3] = [2, 4, 6]\n```\n\n### Dot Product (measure similarity) â­\nMultiply matching positions and add up:\n```\n[1, 2, 3] Â· [4, 5, 6] = 1Ã—4 + 2Ã—5 + 3Ã—6 = 32\n```\n\n**This is HUGE in AI!** The dot product measures how similar two vectors are."
            },
            {
              "type": "code",
              "language": "python",
              "title": "Vector Operations in NumPy",
              "code": "import numpy as np\n\n# Create vectors (just lists of numbers!)\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\n# Vector addition - add matching positions\nprint(f\"a + b = {a + b}\")  # [5, 7, 9]\n\n# Scalar multiplication - multiply every number\nprint(f\"2 * a = {2 * a}\")  # [2, 4, 6]\n\n# Dot product - measures similarity!\nprint(f\"a Â· b = {np.dot(a, b)}\")  # 32\n\n# Magnitude (length) - how 'big' is the vector?\nmagnitude = np.linalg.norm(a)\nprint(f\"|a| = {magnitude:.2f}\")  # 3.74\n\n# Unit vector - same direction, length = 1\nunit_a = a / np.linalg.norm(a)\nprint(f\"Unit vector: {unit_a}\")"
            },
            {
              "type": "text",
              "content": "## Similarity Metrics (How AI Compares Things)\n\n**Euclidean Distance:** Straight-line distance between vectors\n$$d = \\sqrt{\\sum(a_i - b_i)^2}$$\nGood for: Size/magnitude matters (like comparing house prices)\n\n**Cosine Similarity:** Angle between vectors (ignores magnitude)\n$$\\cos(\\theta) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}$$\nGood for: Text similarity (word frequency shouldn't dominate)\n\n**Dot Product:** Raw similarity score\nGood for: Attention mechanisms, fast similarity"
            },
            {
              "type": "text",
              "content": "## Real-World Vector Applications\n\n| Application | How Vectors Are Used |\n|-------------|---------------------|\n| **Word Embeddings** | Words â†’ 300-dim vectors (Word2Vec, BERT) |\n| **Image Search** | Photos â†’ 512-dim vectors (CLIP) |\n| **Recommendations** | Users & items as vectors, find similar |\n| **RAG Systems** | Documents â†’ vectors, search by meaning |\n\n**Example:** \"king\" - \"man\" + \"woman\" â‰ˆ \"queen\"\nVector math captures semantic relationships!"
            }
          ]
        },
        {
          "id": "matrices",
          "title": "Matrices and Matrix Operations",
          "type": "lesson",
          "duration": "30 min",
          "content": [
            {
              "type": "text",
              "content": "## What is a Matrix? (Plain English First!)\n\n**A matrix is a grid of numbers** - like a spreadsheet!\n\n```\n| 1  2  3 |\n| 4  5  6 |\n```\n\nThis is a 2Ã—3 matrix (2 rows, 3 columns).\n\nIn math notation:\n$$A = \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\end{bmatrix}$$\n\nIn code, it's just a list of lists!"
            },
            {
              "type": "text",
              "content": "## Vector Operations\n\n### Addition\nAdd corresponding elements:\n$$\\vec{a} + \\vec{b} = \\begin{bmatrix} a_1 + b_1 \\\\ a_2 + b_2 \\end{bmatrix}$$\n\n### Scalar Multiplication\nMultiply each element by a scalar:\n$$c \\cdot \\vec{v} = \\begin{bmatrix} c \\cdot v_1 \\\\ c \\cdot v_2 \\end{bmatrix}$$\n\n### Dot Product\nSum of element-wise products:\n$$\\vec{a} \\cdot \\vec{b} = \\sum_{i=1}^{n} a_i b_i = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n$$\n\nThe dot product measures **similarity** between vectors - crucial for attention mechanisms!"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Vector Operations in NumPy",
              "code": "import numpy as np\n\n# Create vectors\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\n# Vector addition\nprint(f\"a + b = {a + b}\")  # [5, 7, 9]\n\n# Scalar multiplication\nprint(f\"2 * a = {2 * a}\")  # [2, 4, 6]\n\n# Dot product\nprint(f\"a Â· b = {np.dot(a, b)}\")  # 32\n\n# Magnitude (length) of a vector\nmagnitude = np.linalg.norm(a)\nprint(f\"|a| = {magnitude:.2f}\")  # 3.74\n\n# Unit vector (normalized)\nunit_a = a / np.linalg.norm(a)\nprint(f\"Unit vector: {unit_a}\")"
            },
            {
              "type": "text",
              "content": "## Vector Norms\n\nThe **norm** measures the \"size\" or magnitude of a vector:\n\n**L1 Norm (Manhattan):** $||\\vec{v}||_1 = \\sum |v_i|$\n\n**L2 Norm (Euclidean):** $||\\vec{v}||_2 = \\sqrt{\\sum v_i^2}$\n\n**In ML, norms are used for:**\n- Regularization (L1 for sparsity, L2 for small weights)\n- Measuring distances between points\n- Normalizing vectors (unit vectors)"
            }
          ]
        },
        {
          "id": "matrices",
          "title": "Matrices and Matrix Operations",
          "type": "lesson",
          "duration": "30 min",
          "authorCredits": {
            "keyContributors": ["Arthur Cayley", "James Joseph Sylvester"],
            "historicalNote": "Arthur Cayley formalized matrix algebra in 1858, while his friend J.J. Sylvester coined the term 'matrix'. Their work made possible the compact notation we use for neural network computations today."
          },
          "content": [
            {
              "type": "text",
              "content": "## What is a Matrix?\n\nA **matrix** is a 2D array of numbers arranged in rows and columns. In ML, matrices represent datasets, weights, and transformations.\n\n$$A = \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\end{bmatrix}$$\n\nThis is a $2 \\times 3$ matrix (2 rows, 3 columns).\n\n**Examples in ML:**\n- Dataset: Each row is a sample, each column is a feature\n- Weight matrix: Connects layers in a neural network\n- Attention matrix: Stores attention scores between tokens"
            },
            {
              "type": "text",
              "content": "## Matrix Multiplication\n\nTo multiply matrices $A$ (mÃ—n) and $B$ (nÃ—p), we get result $C$ (mÃ—p):\n\n$$C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj}$$\n\n**Key rule:** Inner dimensions must match!\n- $(3 \\times \\mathbf{4}) \\cdot (\\mathbf{4} \\times 2) = (3 \\times 2)$ âœ“\n- $(3 \\times 4) \\cdot (2 \\times 5)$ âœ— Cannot multiply!\n\n**Why it matters:**\n- Forward pass: $\\text{output} = W \\cdot x + b$\n- Each neuron computes a dot product of inputs and weights"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Matrix Operations in NumPy",
              "code": "import numpy as np\n\n# Create matrices\nA = np.array([[1, 2], \n              [3, 4]])\nB = np.array([[5, 6], \n              [7, 8]])\n\n# Matrix multiplication\nC = A @ B  # or np.matmul(A, B)\nprint(\"A @ B =\")\nprint(C)\n\n# Element-wise multiplication (Hadamard)\nhadamard = A * B\nprint(\"\\nA * B (element-wise) =\")\nprint(hadamard)\n\n# Transpose\nprint(\"\\nA^T =\")\nprint(A.T)\n\n# Neural network layer simulation\ndef linear_layer(X, W, b):\n    \"\"\"Compute Y = XW + b\"\"\"\n    return X @ W + b\n\n# Example: 3 samples, 4 features -> 2 outputs\nX = np.random.randn(3, 4)  # Input\nW = np.random.randn(4, 2)  # Weights\nb = np.random.randn(2)     # Bias\n\nY = linear_layer(X, W, b)\nprint(f\"\\nInput shape: {X.shape}\")\nprint(f\"Output shape: {Y.shape}\")"
            },
            {
              "type": "text",
              "content": "## Special Matrices\n\n**Identity Matrix:** $I \\cdot A = A$\n$$I = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n\n**Diagonal Matrix:** Non-zero only on diagonal\n- Used for scaling operations\n\n**Symmetric Matrix:** $A = A^T$\n- Covariance matrices are symmetric\n\n**Orthogonal Matrix:** $A^T A = I$\n- Preserves lengths and angles"
            }
          ]
        },
        {
          "id": "transformations",
          "title": "Linear Transformations",
          "type": "lesson",
          "duration": "25 min",
          "content": [
            {
              "type": "mermaid",
              "title": "Neural Network as Transformations",
              "code": "flowchart LR\n    subgraph Layer1[\"Layer 1\"]\n        X[Input X] --> W1[\"W1 x\"]\n        W1 --> A1[\"+ b1\"]\n        A1 --> R1[ReLU]\n    end\n    \n    subgraph Layer2[\"Layer 2\"]\n        R1 --> W2[\"W2 x\"]\n        W2 --> A2[\"+ b2\"]\n        A2 --> R2[ReLU]\n    end\n    \n    R2 --> OUT[Output Y]"
            },
            {
              "type": "text",
              "content": "## Matrices as Transformations\n\nA matrix multiplication $y = Ax$ transforms vector $x$ into vector $y$. This is a **linear transformation**.\n\n**Common transformations:**\n- **Scaling:** Stretch or shrink\n- **Rotation:** Rotate around origin\n- **Shearing:** Slant the space\n- **Projection:** Map to lower dimension\n\n**In neural networks:**\n- Each layer transforms the input space\n- Learning = finding the right transformations"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Visualizing Transformations",
              "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Original points (unit square)\npoints = np.array([[0, 0], [1, 0], [1, 1], [0, 1], [0, 0]]).T\n\n# Transformation matrices\nrotation_45 = np.array([[0.707, -0.707],\n                        [0.707,  0.707]])\n\nscaling = np.array([[2, 0],\n                    [0, 0.5]])\n\nshear = np.array([[1, 0.5],\n                  [0, 1]])\n\n# Apply transformations\nrotated = rotation_45 @ points\nscaled = scaling @ points\nsheared = shear @ points\n\nprint(\"Original shape:\", points.shape)\nprint(\"Transformed shape:\", rotated.shape)\nprint(\"\\nEach column is a point (x, y)\")"
            },
            {
              "type": "text",
              "content": "## Common Activation Functions\n\n| Function | Formula | Range | When to Use |\n|----------|---------|-------|-------------|\n| **Sigmoid** | $\\sigma(x) = \\frac{1}{1+e^{-x}}$ | (0, 1) | Binary output, gates |\n| **Tanh** | $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$ | (-1, 1) | Hidden layers (centered) |\n| **ReLU** | $\\max(0, x)$ | [0, âˆž) | Default for hidden layers |\n| **Softmax** | $\\frac{e^{x_i}}{\\sum e^{x_j}}$ | (0, 1), sums to 1 | Multi-class output |\n\n**Why ReLU dominates:** Fast to compute, doesn't saturate for positive values, reduces vanishing gradient problem."
            },
            {
              "type": "text",
              "content": "## The Big Picture\n\nA neural network is a series of:\n1. **Linear transformations** (matrix multiply)\n2. **Non-linear activations** (ReLU, sigmoid)\n\n$$\\text{Layer: } f(x) = \\sigma(Wx + b)$$\n\nWithout non-linearity, stacking layers would just be one big matrix multiply. The activation functions let us model complex, non-linear relationships!\n\n**Each neuron computes:**\n$$z = \\sum_{i=1}^{n} w_i x_i + b \\quad \\text{(weighted sum)}$$\n$$a = \\sigma(z) \\quad \\text{(activation)}$$"
            }
          ]
        },
        {
          "id": "eigenvalues",
          "title": "Eigenvalues and Eigenvectors",
          "type": "lesson",
          "duration": "30 min",
          "content": [
            {
              "type": "text",
              "content": "## What are Eigenvectors?\n\nAn **eigenvector** of matrix $A$ is a vector that only gets scaled (not rotated) when transformed by $A$:\n\n$$A\\vec{v} = \\lambda\\vec{v}$$\n\nWhere:\n- $\\vec{v}$ is the eigenvector\n- $\\lambda$ is the eigenvalue (the scaling factor)\n\n**Intuition:** Eigenvectors are the \"natural axes\" of a transformation."
            },
            {
              "type": "text",
              "content": "## Why They Matter in ML\n\n**1. PCA (Principal Component Analysis)**\n- Eigenvectors of covariance matrix = principal components\n- Eigenvalues = variance explained by each component\n- Used for dimensionality reduction\n\n**2. Stability Analysis**\n- Eigenvalues determine if gradients explode or vanish\n- RNNs suffer when eigenvalues > 1 (exploding) or < 1 (vanishing)\n\n**3. Graph Neural Networks**\n- Eigenvalues of graph Laplacian reveal structure\n- Spectral clustering uses eigenvectors"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Computing Eigenvalues in NumPy",
              "code": "import numpy as np\n\n# Covariance matrix (symmetric)\nA = np.array([[4, 2],\n              [2, 3]])\n\n# Compute eigenvalues and eigenvectors\neigenvalues, eigenvectors = np.linalg.eig(A)\n\nprint(\"Eigenvalues:\", eigenvalues)\nprint(\"\\nEigenvectors (columns):\")\nprint(eigenvectors)\n\n# Verify: A @ v = lambda * v\nv1 = eigenvectors[:, 0]\nlambda1 = eigenvalues[0]\n\nprint(f\"\\nA @ v1 = {A @ v1}\")\nprint(f\"Î»1 * v1 = {lambda1 * v1}\")\nprint(\"They match!\")\n\n# PCA Example\nfrom sklearn.decomposition import PCA\n\n# Random data\nX = np.random.randn(100, 5)\n\n# PCA finds eigenvectors of covariance matrix\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\n\nprint(f\"\\nOriginal shape: {X.shape}\")\nprint(f\"Reduced shape: {X_reduced.shape}\")\nprint(f\"Variance explained: {pca.explained_variance_ratio_}\")"
            }
          ]
        },
        {
          "id": "svd",
          "title": "Singular Value Decomposition (SVD)",
          "type": "lesson",
          "duration": "30 min",
          "authorCredits": {
            "keyContributors": ["Gene Golub", "William Kahan"],
            "historicalNote": "The modern SVD algorithm was developed by Gene Golub and William Kahan in 1965. SVD is often called 'the most important matrix factorization' and powers everything from PCA to recommender systems."
          },
          "content": [
            {
              "type": "text",
              "content": "## What is SVD?\n\n**Singular Value Decomposition** factors any matrix into three components:\n\n$$A = U \\Sigma V^T$$\n\nWhere:\n- $U$ = left singular vectors (rotation in output space)\n- $\\Sigma$ = diagonal matrix of singular values (scaling)\n- $V^T$ = right singular vectors (rotation in input space)\n\n**Key Insight:** Every linear transformation is a rotation, then a stretch, then another rotation."
            },
            {
              "type": "text",
              "content": "## Why SVD is Everywhere in ML\n\n**1. Dimensionality Reduction (PCA)**\n- PCA is SVD applied to centered data\n- Keep top-k singular values â†’ keep most variance\n- Compression with minimal information loss\n\n**2. Recommender Systems**\n- Netflix Prize: SVD on user-item matrices\n- Find latent factors (genres, preferences)\n- Fill in missing ratings\n\n**3. NLP: LSA/LSI**\n- Latent Semantic Analysis uses SVD\n- Reduce word-document matrices\n- Capture semantic relationships\n\n**4. Image Compression**\n- Low-rank approximation of image matrices\n- Keep top singular values"
            },
            {
              "type": "text",
              "content": "## The Power of Low-Rank Approximation\n\nThe **Eckart-Young theorem** states:\n\n*The best rank-k approximation of a matrix (in terms of Frobenius norm) is obtained by keeping only the top k singular values.*\n\n$$A_k = U_k \\Sigma_k V_k^T$$\n\nThis is why SVD is so powerful for compression and noise reduction."
            },
            {
              "type": "code",
              "language": "python",
              "title": "SVD in Practice",
              "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# SVD decomposes ANY matrix\nA = np.array([[1, 2, 3],\n              [4, 5, 6],\n              [7, 8, 9]])\n\nU, S, Vt = np.linalg.svd(A)\n\nprint(\"Original A:\")\nprint(A)\nprint(f\"\\nSingular values: {S}\")\nprint(f\"U shape: {U.shape}, S shape: {S.shape}, Vt shape: {Vt.shape}\")\n\n# Reconstruct from SVD\nA_reconstructed = U @ np.diag(S) @ Vt\nprint(f\"\\nReconstruction error: {np.abs(A - A_reconstructed).max():.2e}\")\n\n# Low-rank approximation (keep only top-k)\ndef low_rank_approx(A, k):\n    U, S, Vt = np.linalg.svd(A, full_matrices=False)\n    return U[:, :k] @ np.diag(S[:k]) @ Vt[:k, :]\n\n# Example: Compress a simple matrix\nA_rank1 = low_rank_approx(A, k=1)\nA_rank2 = low_rank_approx(A, k=2)\n\nprint(\"\\nRank-1 approximation:\")\nprint(A_rank1.round(2))\nprint(\"\\nRank-2 approximation:\")\nprint(A_rank2.round(2))"
            },
            {
              "type": "text",
              "content": "## SVD vs Eigendecomposition\n\n| Feature | SVD | Eigendecomposition |\n|---------|-----|--------------------|\n| Works on | Any matrix | Square matrices |\n| Components | U, Î£, V^T | V, Î›, V^-1 |\n| Values | Always non-negative | Can be negative |\n| Vectors | Always orthogonal | Not always |\n| Use case | General purpose | Symmetric matrices |\n\n**Bottom line:** When in doubt, use SVD - it always works."
            },
            {
              "type": "text",
              "content": "## When to Use SVD\n\nâœ… **Use SVD when:**\n- Dimensionality reduction is needed\n- Building recommender systems\n- Text analysis (LSA/LSI)\n- Need stable matrix computations\n- Computing pseudo-inverse\n\nâš ï¸ **Limitations:**\n- O(mnÂ²) or O(mÂ²n) complexity - expensive for huge matrices\n- For large-scale, use randomized/truncated SVD (e.g., sklearn.decomposition.TruncatedSVD)\n- Not ideal for sparse matrices - consider NMF instead"
            }
          ]
        },
        {
          "id": "la-quiz",
          "title": "Linear Algebra Quiz",
          "type": "quiz",
          "duration": "10 min",
          "questions": [
            {
              "question": "What does the dot product of two vectors measure?",
              "options": [
                "Their difference",
                "Their similarity",
                "Their product",
                "Their sum"
              ],
              "correct": 1,
              "explanation": "The dot product measures how aligned two vectors are. It's maximized when vectors point the same direction and zero when perpendicular."
            },
            {
              "question": "For matrix multiplication A(3Ã—4) @ B(4Ã—2), what is the result shape?",
              "options": [
                "3Ã—2",
                "4Ã—4",
                "3Ã—4",
                "2Ã—3"
              ],
              "correct": 0,
              "explanation": "Matrix multiplication: (mÃ—n) @ (nÃ—p) = (mÃ—p). So (3Ã—4) @ (4Ã—2) = (3Ã—2)."
            },
            {
              "question": "In the equation Av = Î»v, what is Î»?",
              "options": [
                "Eigenvector",
                "Eigenvalue",
                "Determinant",
                "Trace"
              ],
              "correct": 1,
              "explanation": "Î» (lambda) is the eigenvalue - the scalar that the eigenvector is multiplied by after the transformation."
            },
            {
              "question": "What is the purpose of normalizing a vector (making it a unit vector)?",
              "options": [
                "To make it faster to compute",
                "To make its magnitude equal to 1 while preserving direction",
                "To convert it to a matrix",
                "To calculate its eigenvalue"
              ],
              "correct": 1,
              "explanation": "Normalizing creates a unit vector with magnitude 1. This is essential for cosine similarity calculations and prevents magnitude from affecting comparisons."
            },
            {
              "question": "In a neural network layer y = Wx + b, what is the role of the weight matrix W?",
              "options": [
                "It adds bias to the output",
                "It transforms the input features through linear combination",
                "It activates the neurons",
                "It stores the training data"
              ],
              "correct": 1,
              "explanation": "The weight matrix W performs a linear transformation, combining and weighting input features to produce new representations."
            }
          ],
          "references": {
            "lessonRefs": [
              "vectors",
              "matrices",
              "eigenvalues"
            ],
            "externalRefs": [
              {
                "title": "IBM: Vector Embeddings",
                "url": "https://www.ibm.com/topics/vector-embedding"
              },
              {
                "title": "3Blue1Brown Linear Algebra",
                "url": "https://www.3blue1brown.com/topics/linear-algebra"
              },
              {
                "title": "Khan Academy Linear Algebra",
                "url": "https://www.khanacademy.org/math/linear-algebra"
              }
            ]
          }
        }
      ]
    },
    {
      "id": "calculus",
      "title": "Calculus for Optimization",
      "description": "Derivatives, gradients, and the chain rule - how neural networks learn",
      "lessons": [
        {
          "id": "derivatives",
          "title": "Derivatives and Slopes",
          "type": "lesson",
          "duration": "25 min",
          "authorCredits": {
            "keyContributors": ["Isaac Newton", "Gottfried Leibniz"],
            "historicalNote": "Newton and Leibniz independently invented calculus in the 1680s. Newton's notation (fluxions) and Leibniz's notation (dy/dx) both contribute to modern calculus. We primarily use Leibniz notation today."
          },
          "content": [
            {
              "type": "text",
              "content": "## What is a Derivative?\n\nThe **derivative** measures how fast a function changes at a point. It's the slope of the tangent line.\n\n$$f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$\n\n**Intuition:** If $f(x)$ is your position, $f'(x)$ is your velocity.\n\n**Common derivatives:**\n- $\\frac{d}{dx}(x^n) = nx^{n-1}$\n- $\\frac{d}{dx}(e^x) = e^x$\n- $\\frac{d}{dx}(\\ln x) = \\frac{1}{x}$"
            },
            {
              "type": "text",
              "content": "## Why Derivatives Matter for ML\n\nTraining a neural network means finding weights that **minimize the loss function**.\n\nThe derivative tells us:\n- **Which direction** to move (sign of derivative)\n- **How much** to move (magnitude of derivative)\n\n$$w_{new} = w_{old} - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$\n\nThis is **gradient descent** - the heart of deep learning!"
            },
            {
              "type": "text",
              "content": "## The Training Loop (How Models Learn)\n\n```\n1. FORWARD PASS: Input flows through network â†’ Prediction\n2. LOSS: Compare prediction to truth â†’ Error number\n3. BACKWARD PASS: Compute gradients via chain rule\n4. UPDATE: Adjust weights opposite to gradient\n5. REPEAT for thousands of batches\n```\n\n**Each step refines the model.** Over time, loss decreases and accuracy improves.\n\nThis loop runs millions of times when training models like GPT!"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Computing Derivatives",
              "code": "import numpy as np\n\n# Numerical derivative\ndef numerical_derivative(f, x, h=1e-5):\n    \"\"\"Compute derivative using finite differences\"\"\"\n    return (f(x + h) - f(x - h)) / (2 * h)\n\n# Example: f(x) = x^2\nf = lambda x: x**2\n\n# At x = 3, derivative should be 2*3 = 6\nderiv = numerical_derivative(f, 3)\nprint(f\"f(x) = xÂ², f'(3) = {deriv:.4f}\")  # ~6.0\n\n# Loss function example\ndef mse_loss(y_pred, y_true):\n    return np.mean((y_pred - y_true)**2)\n\n# Derivative of MSE with respect to predictions\ndef mse_gradient(y_pred, y_true):\n    return 2 * (y_pred - y_true) / len(y_true)\n\ny_true = np.array([1, 2, 3])\ny_pred = np.array([1.1, 2.2, 2.8])\n\nprint(f\"\\nLoss: {mse_loss(y_pred, y_true):.4f}\")\nprint(f\"Gradient: {mse_gradient(y_pred, y_true)}\")"
            }
          ]
        },
        {
          "id": "gradients",
          "title": "Gradients and Partial Derivatives",
          "type": "lesson",
          "duration": "30 min",
          "content": [
            {
              "type": "text",
              "content": "## From 1D to Multiple Dimensions\n\nWhen a function has multiple inputs, we take **partial derivatives** with respect to each input:\n\n$$f(x, y) = x^2 + xy + y^2$$\n\n$$\\frac{\\partial f}{\\partial x} = 2x + y \\quad \\frac{\\partial f}{\\partial y} = x + 2y$$\n\nThe **gradient** is a vector of all partial derivatives:\n\n$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{bmatrix}$$"
            },
            {
              "type": "text",
              "content": "## The Gradient Points Uphill\n\nThe gradient $\\nabla f$ points in the direction of **steepest increase**.\n\nTo minimize the loss:\n- Move in the **opposite direction** of the gradient\n- This is gradient descent!\n\n$$\\theta_{new} = \\theta_{old} - \\alpha \\nabla L(\\theta)$$\n\nWhere $\\alpha$ is the learning rate."
            },
            {
              "type": "code",
              "language": "python",
              "title": "Gradient Descent from Scratch",
              "code": "import numpy as np\n\n# Function to minimize: f(x,y) = xÂ² + yÂ² (bowl shape)\ndef f(params):\n    x, y = params\n    return x**2 + y**2\n\ndef gradient(params):\n    x, y = params\n    return np.array([2*x, 2*y])\n\n# Gradient descent\ndef gradient_descent(start, lr=0.1, n_steps=20):\n    params = np.array(start, dtype=float)\n    history = [params.copy()]\n    \n    for i in range(n_steps):\n        grad = gradient(params)\n        params = params - lr * grad\n        history.append(params.copy())\n        \n        if i % 5 == 0:\n            print(f\"Step {i}: params={params}, f={f(params):.4f}\")\n    \n    return params, history\n\n# Start at (5, 5), should converge to (0, 0)\nfinal, history = gradient_descent([5.0, 5.0])\nprint(f\"\\nFinal: {final}, f={f(final):.6f}\")"
            }
          ]
        },
        {
          "id": "chain-rule",
          "title": "The Chain Rule and Backpropagation",
          "type": "lesson",
          "duration": "35 min",
          "content": [
            {
              "type": "text",
              "content": "## The Chain Rule\n\nWhen functions are composed, the chain rule lets us find the derivative:\n\n$$\\frac{d}{dx} f(g(x)) = f'(g(x)) \\cdot g'(x)$$\n\n**Example:** If $y = (3x + 2)^2$\n- Let $u = 3x + 2$, so $y = u^2$\n- $\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx} = 2u \\cdot 3 = 6(3x+2)$"
            },
            {
              "type": "text",
              "content": "## Backpropagation = Chain Rule\n\nA neural network is a composition of functions:\n$$\\text{output} = f_3(f_2(f_1(x)))$$\n\nTo find how the loss depends on early weights, we chain the derivatives:\n\n$$\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial y_3} \\cdot \\frac{\\partial y_3}{\\partial y_2} \\cdot \\frac{\\partial y_2}{\\partial y_1} \\cdot \\frac{\\partial y_1}{\\partial w_1}$$\n\n**This is backpropagation!** We compute gradients layer by layer, from output back to input."
            },
            {
              "type": "text",
              "content": "## Why Backpropagation is Brilliant\n\n**The Naive Approach:**\nTo compute gradient for 1 million weights, you'd need 1,000,001 forward passes:\n- 1 baseline pass\n- 1 pass per weight to measure its effect\n\n**Backpropagation:**\nComputes the ENTIRE gradient in just **2 passes**:\n1. One forward pass\n2. One backward pass\n\n**That's why deep learning is possible!** Without backprop, training would be millions of times slower.\n\n*Historical note: Formalized by Rumelhart, Hinton & Williams in 1986*"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Backprop Through a Simple Network",
              "code": "import numpy as np\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    s = sigmoid(x)\n    return s * (1 - s)\n\n# Simple 2-layer network\nclass SimpleNetwork:\n    def __init__(self):\n        self.w1 = np.random.randn(2, 3) * 0.5\n        self.w2 = np.random.randn(3, 1) * 0.5\n    \n    def forward(self, x):\n        # Store for backprop\n        self.x = x\n        self.z1 = x @ self.w1\n        self.a1 = sigmoid(self.z1)\n        self.z2 = self.a1 @ self.w2\n        self.output = sigmoid(self.z2)\n        return self.output\n    \n    def backward(self, y_true, lr=0.1):\n        # Output layer gradient (chain rule!)\n        dL_dz2 = (self.output - y_true) * sigmoid_derivative(self.z2)\n        dL_dw2 = self.a1.T @ dL_dz2\n        \n        # Hidden layer gradient (chain rule continues!)\n        dL_da1 = dL_dz2 @ self.w2.T\n        dL_dz1 = dL_da1 * sigmoid_derivative(self.z1)\n        dL_dw1 = self.x.T @ dL_dz1\n        \n        # Update weights\n        self.w2 -= lr * dL_dw2\n        self.w1 -= lr * dL_dw1\n\n# Train on XOR problem\nX = np.array([[0,0], [0,1], [1,0], [1,1]])\ny = np.array([[0], [1], [1], [0]])\n\nnet = SimpleNetwork()\nfor epoch in range(1000):\n    pred = net.forward(X)\n    net.backward(y)\n    if epoch % 200 == 0:\n        loss = np.mean((pred - y)**2)\n        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")"
            }
          ]
        },
        {
          "id": "calculus-quiz",
          "title": "Calculus Quiz",
          "type": "quiz",
          "duration": "10 min",
          "questions": [
            {
              "question": "What does the gradient of a loss function tell us?",
              "options": [
                "The minimum value",
                "The direction of steepest increase",
                "The learning rate",
                "The final weights"
              ],
              "correct": 1,
              "explanation": "The gradient points in the direction of steepest increase. We move opposite to it to minimize the loss."
            },
            {
              "question": "What mathematical concept is backpropagation based on?",
              "options": [
                "Matrix multiplication",
                "The chain rule",
                "Eigenvalues",
                "Integration"
              ],
              "correct": 1,
              "explanation": "Backpropagation uses the chain rule to compute gradients through composed functions (layers)."
            },
            {
              "question": "What is the purpose of the learning rate in gradient descent?",
              "options": [
                "To determine the model architecture",
                "To control the step size when updating weights",
                "To calculate the loss function",
                "To normalize the gradients"
              ],
              "correct": 1,
              "explanation": "The learning rate controls how much we adjust weights in the direction opposite to the gradient. Too high causes instability, too low causes slow learning."
            },
            {
              "question": "What happens if the gradient at a point is zero?",
              "options": [
                "The model crashes",
                "We've found a critical point (minimum, maximum, or saddle point)",
                "The learning rate becomes infinite",
                "The model resets to initial weights"
              ],
              "correct": 1,
              "explanation": "A zero gradient indicates a critical point. In optimization, we hope it's a minimum (ideally global), but it could be a maximum or saddle point."
            },
            {
              "question": "Why is the chain rule essential for training deep networks?",
              "options": [
                "It encrypts the gradients for security",
                "It allows gradients to flow backward through composed functions",
                "It initializes the weights",
                "It defines the network architecture"
              ],
              "correct": 1,
              "explanation": "Deep networks are compositions of functions. The chain rule lets us compute how changes in early layers affect the final loss by multiplying gradients layer by layer."
            }
          ],
          "references": {
            "lessonRefs": [
              "derivatives",
              "gradients",
              "chain-rule"
            ],
            "externalRefs": [
              {
                "title": "IBM: Backpropagation",
                "url": "https://www.ibm.com/topics/backpropagation"
              },
              {
                "title": "3Blue1Brown Calculus",
                "url": "https://www.3blue1brown.com/topics/calculus"
              },
              {
                "title": "Calculus for ML",
                "url": "https://explained.ai/matrix-calculus/"
              }
            ]
          }
        }
      ]
    },
    {
      "id": "probability",
      "title": "Probability and Statistics",
      "description": "Uncertainty, distributions, and Bayesian thinking for ML",
      "lessons": [
        {
          "id": "probability-basics",
          "title": "Probability Fundamentals",
          "type": "lesson",
          "duration": "25 min",
          "content": [
            {
              "type": "text",
              "content": "## Why Probability in ML?\n\nMachine learning is fundamentally about **uncertainty**:\n- Data has noise\n- Predictions are uncertain\n- We want to quantify confidence\n\n**Probability** gives us a framework to reason about uncertainty mathematically."
            },
            {
              "type": "text",
              "content": "## Basic Rules\n\n**Probability of event A:** $0 \\leq P(A) \\leq 1$\n\n**Complement:** $P(\\text{not } A) = 1 - P(A)$\n\n**Addition (OR):** $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n\n**Multiplication (AND):**\n- Independent: $P(A \\cap B) = P(A) \\cdot P(B)$\n- Dependent: $P(A \\cap B) = P(A) \\cdot P(B|A)$\n\n**Conditional probability:**\n$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Probability with Python",
              "code": "import numpy as np\n\n# Simulating probabilities\nnp.random.seed(42)\n\n# Fair coin flips\nflips = np.random.choice(['H', 'T'], size=10000)\nprint(f\"P(Heads) â‰ˆ {np.mean(flips == 'H'):.3f}\")\n\n# Rolling dice\nrolls = np.random.randint(1, 7, size=10000)\nprint(f\"P(roll = 6) â‰ˆ {np.mean(rolls == 6):.3f}\")\nprint(f\"P(roll >= 5) â‰ˆ {np.mean(rolls >= 5):.3f}\")\n\n# Joint probability (two dice)\ndice1 = np.random.randint(1, 7, size=10000)\ndice2 = np.random.randint(1, 7, size=10000)\n\n# P(both = 6)\np_both_6 = np.mean((dice1 == 6) & (dice2 == 6))\nprint(f\"\\nP(both dice = 6) â‰ˆ {p_both_6:.4f}\")\nprint(f\"Theoretical: {1/6 * 1/6:.4f}\")"
            }
          ]
        },
        {
          "id": "distributions",
          "title": "Probability Distributions",
          "type": "lesson",
          "duration": "30 min",
          "content": [
            {
              "type": "text",
              "content": "## What is a Distribution?\n\nA **probability distribution** describes all possible values and their probabilities.\n\n**Discrete distributions:** Countable outcomes (coin flips, dice)\n**Continuous distributions:** Infinite outcomes (heights, weights)"
            },
            {
              "type": "text",
              "content": "## Key Distributions for ML\n\n### Normal (Gaussian)\n$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n- Bell-shaped curve\n- Defined by mean ($\\mu$) and standard deviation ($\\sigma$)\n- Central limit theorem: Sums tend toward normal\n- Weight initialization, noise, errors\n\n### Bernoulli\n- Single binary outcome (0 or 1)\n- Parameter: $p$ (probability of success)\n- Binary classification outputs\n\n### Categorical\n- Multiple discrete outcomes\n- Softmax outputs in classification"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Working with Distributions",
              "code": "import numpy as np\nfrom scipy import stats\n\n# Normal distribution\nmu, sigma = 0, 1  # Standard normal\nnormal = stats.norm(mu, sigma)\n\nprint(\"Normal Distribution (Î¼=0, Ïƒ=1):\")\nprint(f\"P(X < 0) = {normal.cdf(0):.3f}\")      # 0.5\nprint(f\"P(-1 < X < 1) = {normal.cdf(1) - normal.cdf(-1):.3f}\")  # ~0.68\nprint(f\"P(-2 < X < 2) = {normal.cdf(2) - normal.cdf(-2):.3f}\")  # ~0.95\n\n# Sample from distributions\nsamples = np.random.normal(mu, sigma, 1000)\nprint(f\"\\nSample mean: {samples.mean():.3f}\")\nprint(f\"Sample std: {samples.std():.3f}\")\n\n# Bernoulli (coin flip)\np = 0.7\nbernoulli_samples = np.random.binomial(1, p, 1000)\nprint(f\"\\nBernoulli (p=0.7): Mean = {bernoulli_samples.mean():.3f}\")\n\n# Softmax (converts logits to probabilities)\ndef softmax(logits):\n    exp_logits = np.exp(logits - np.max(logits))\n    return exp_logits / exp_logits.sum()\n\nlogits = np.array([2.0, 1.0, 0.1])\nprobs = softmax(logits)\nprint(f\"\\nSoftmax: {logits} -> {probs.round(3)}\")\nprint(f\"Sum = {probs.sum():.3f}\")"
            }
          ]
        },
        {
          "id": "bayes",
          "title": "Bayes' Theorem",
          "type": "lesson",
          "duration": "30 min",
          "authorCredits": {
            "keyContributors": ["Thomas Bayes", "Pierre-Simon Laplace"],
            "historicalNote": "Reverend Thomas Bayes developed the theorem posthumously published in 1763. Laplace independently rediscovered and generalized it, applying it extensively. Bayesian inference now underlies probabilistic ML, uncertainty quantification, and even large language models."
          },
          "content": [
            {
              "type": "text",
              "content": "## Bayes' Theorem\n\n$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n\n**In words:**\n$$\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Evidence}}$$\n\n**Bayes lets us update our beliefs given new evidence.**"
            },
            {
              "type": "text",
              "content": "## Example: Medical Testing\n\n- Disease prevalence: 1% (prior)\n- Test accuracy: 99% (true positive rate)\n- False positive rate: 5%\n\n**Question:** If test is positive, what's the probability of disease?\n\n$$P(D|+) = \\frac{P(+|D) \\cdot P(D)}{P(+)}$$\n\n$$= \\frac{0.99 \\times 0.01}{0.99 \\times 0.01 + 0.05 \\times 0.99} = \\frac{0.0099}{0.0594} \\approx 17\\%$$\n\n**Surprising!** A positive test only means 17% chance of disease because the disease is rare."
            },
            {
              "type": "text",
              "content": "## Bayes in ML\n\n**Bayesian inference:** Update model beliefs with data\n- Prior: What we believe before seeing data\n- Likelihood: How well model explains data\n- Posterior: Updated beliefs\n\n**Applications:**\n- Naive Bayes classifiers\n- Bayesian neural networks\n- Uncertainty quantification\n- Hyperparameter optimization (Bayesian optimization)"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Naive Bayes Classifier",
              "code": "from sklearn.naive_bayes import GaussianNB\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data\niris = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, test_size=0.3, random_state=42\n)\n\n# Train Naive Bayes\nnb = GaussianNB()\nnb.fit(X_train, y_train)\n\n# Evaluate\naccuracy = nb.score(X_test, y_test)\nprint(f\"Naive Bayes Accuracy: {accuracy:.3f}\")\n\n# Get probability predictions\nprobs = nb.predict_proba(X_test[:3])\nprint(f\"\\nProbabilities for first 3 samples:\")\nfor i, p in enumerate(probs):\n    print(f\"  Sample {i}: {p.round(3)}\")"
            }
          ]
        },
        {
          "id": "information-theory",
          "title": "Information Theory Essentials",
          "type": "lesson",
          "duration": "30 min",
          "authorCredits": {
            "keyContributors": ["Claude Shannon"],
            "historicalNote": "Claude Shannon's 1948 paper 'A Mathematical Theory of Communication' founded information theory. His concept of entropy directly underlies the cross-entropy loss function used to train virtually every modern neural network."
          },
          "content": [
            {
              "type": "text",
              "content": "## Why Information Theory for ML?\n\n**Information theory** provides the mathematical foundation for:\n- **Cross-entropy loss** (the most common loss function)\n- **KL divergence** (comparing distributions)\n- **Compression** and representation learning\n- **Information bottleneck** theory\n\n> *\"Information theory answers: How much can you compress a message?\"* â€” Claude Shannon"
            },
            {
              "type": "text",
              "content": "## Entropy: Measuring Uncertainty\n\n**Entropy** measures the average \"surprise\" or uncertainty in a distribution:\n\n$$H(P) = -\\sum_x P(x) \\log P(x)$$\n\n**Intuition:**\n- Coin flip (50/50): High entropy (uncertain)\n- Loaded coin (99/1): Low entropy (predictable)\n- Certainty (100/0): Zero entropy\n\n**In ML:** Higher entropy = more uncertain predictions"
            },
            {
              "type": "text",
              "content": "## Cross-Entropy: Comparing Distributions\n\n**Cross-entropy** measures the average bits needed to encode samples from P using a code optimized for Q:\n\n$$H(P, Q) = -\\sum_x P(x) \\log Q(x)$$\n\n**In classification:**\n- $P$ = true labels (one-hot)\n- $Q$ = model predictions (softmax)\n- Cross-entropy loss = how wrong your predictions are\n\n$$\\text{Loss} = -\\sum_c y_c \\log(\\hat{y}_c)$$\n\nThis is **exactly** the categorical cross-entropy loss!"
            },
            {
              "type": "text",
              "content": "## KL Divergence: Distance Between Distributions\n\n**Kullback-Leibler divergence** measures how different Q is from P:\n\n$$D_{KL}(P||Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}$$\n\n**Properties:**\n- Always â‰¥ 0 (Gibbs' inequality)\n- = 0 only when P = Q\n- **Asymmetric:** $D_{KL}(P||Q) \\neq D_{KL}(Q||P)$\n\n**In ML:**\n- VAEs minimize KL divergence to prior\n- Knowledge distillation uses KL divergence\n- Regularization in Bayesian methods"
            },
            {
              "type": "text",
              "content": "## The Connection\n\n$$H(P, Q) = H(P) + D_{KL}(P||Q)$$\n\n**Cross-entropy = Entropy + KL Divergence**\n\nSince entropy of true labels $H(P)$ is constant during training, minimizing cross-entropy = minimizing KL divergence = making Q closer to P!"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Information Theory in Practice",
              "code": "import numpy as np\nfrom scipy.stats import entropy\nfrom scipy.special import rel_entr\n\n# Entropy: measure uncertainty\ndef compute_entropy(p):\n    p = np.array(p)\n    p = p[p > 0]  # Avoid log(0)\n    return -np.sum(p * np.log2(p))\n\n# Examples\nfair_coin = [0.5, 0.5]\nloaded_coin = [0.9, 0.1]\ncertain = [1.0, 0.0]\n\nprint(\"Entropy (bits):\")\nprint(f\"  Fair coin: {compute_entropy(fair_coin):.3f}\")\nprint(f\"  Loaded coin: {compute_entropy(loaded_coin):.3f}\")\nprint(f\"  Certain: {compute_entropy(certain):.3f}\")\n\n# Cross-entropy loss\ndef cross_entropy(y_true, y_pred, eps=1e-15):\n    y_pred = np.clip(y_pred, eps, 1 - eps)\n    return -np.sum(y_true * np.log(y_pred))\n\n# True label: class 1 (one-hot)\ny_true = [0, 1, 0]  \n\n# Good prediction\ny_good = [0.1, 0.8, 0.1]\n# Bad prediction\ny_bad = [0.4, 0.3, 0.3]\n\nprint(f\"\\nCross-entropy loss:\")\nprint(f\"  Good prediction: {cross_entropy(y_true, y_good):.3f}\")\nprint(f\"  Bad prediction: {cross_entropy(y_true, y_bad):.3f}\")\n\n# KL Divergence\nP = np.array([0.3, 0.7])\nQ = np.array([0.5, 0.5])\n\nkl_div = np.sum(rel_entr(P, Q))\nprint(f\"\\nKL(P||Q) = {kl_div:.4f}\")\nprint(f\"KL(Q||P) = {np.sum(rel_entr(Q, P)):.4f}\")\nprint(\"Note: KL is asymmetric!\")"
            },
            {
              "type": "text",
              "content": "## When to Use What\n\n| Concept | Use When | ML Example |\n|---------|----------|------------|\n| **Entropy** | Measuring uncertainty | Confidence calibration |\n| **Cross-entropy** | Classification loss | Training classifiers |\n| **KL Divergence** | Comparing distributions | VAEs, knowledge distillation |\n| **Mutual Information** | Feature selection | Finding relevant features |"
            }
          ]
        },
        {
          "id": "stats-quiz",
          "title": "Probability Quiz",
          "type": "quiz",
          "duration": "10 min",
          "questions": [
            {
              "question": "What distribution is most commonly used for weight initialization?",
              "options": [
                "Uniform",
                "Normal (Gaussian)",
                "Bernoulli",
                "Poisson"
              ],
              "correct": 1,
              "explanation": "Normal distribution is commonly used for weight initialization (e.g., Xavier/He initialization)."
            },
            {
              "question": "In Bayes' theorem, what does the 'prior' represent?",
              "options": [
                "Evidence from data",
                "Belief before seeing data",
                "The likelihood",
                "The posterior"
              ],
              "correct": 1,
              "explanation": "The prior represents our belief about a parameter before observing any data."
            },
            {
              "question": "What is the 68-95-99.7 rule for normal distributions?",
              "options": [
                "Percentages of data at different temperatures",
                "Percentages of data within 1, 2, and 3 standard deviations from the mean",
                "Probabilities of model failure",
                "Ratios of training to test data"
              ],
              "correct": 1,
              "explanation": "In a normal distribution, ~68% of data falls within Â±1Ïƒ, ~95% within Â±2Ïƒ, and ~99.7% within Â±3Ïƒ from the mean."
            },
            {
              "question": "What is the softmax function used for in classification?",
              "options": [
                "To make the model softer",
                "To convert logits to a probability distribution summing to 1",
                "To reduce the learning rate",
                "To initialize weights"
              ],
              "correct": 1,
              "explanation": "Softmax exponentiates logits and normalizes them, producing a probability distribution where all outputs sum to 1, useful for multi-class classification."
            },
            {
              "question": "What does maximum likelihood estimation (MLE) try to find?",
              "options": [
                "The largest dataset",
                "Parameters that make the observed data most probable",
                "The maximum number of layers",
                "The fastest training method"
              ],
              "correct": 1,
              "explanation": "MLE finds parameter values that maximize the likelihood (probability) of observing the training data under the model."
            }
          ],
          "references": {
            "lessonRefs": [
              "probability-basics",
              "distributions",
              "bayes"
            ],
            "externalRefs": [
              {
                "title": "StatQuest (YouTube)",
                "url": "https://www.youtube.com/c/joshstarmer"
              },
              {
                "title": "Seeing Theory",
                "url": "https://seeing-theory.brown.edu/"
              }
            ]
          }
        }
      ]
    },
    {
      "id": "optimization",
      "title": "Optimization Techniques",
      "description": "From vanilla gradient descent to Adam - how models learn",
      "lessons": [
        {
          "id": "loss-functions",
          "title": "Loss Functions",
          "type": "lesson",
          "duration": "25 min",
          "content": [
            {
              "type": "text",
              "content": "## What is a Loss Function?\n\nA **loss function** (or cost function) measures how wrong the model's predictions are. Training minimizes this loss.\n\n**Properties of good loss functions:**\n- Lower is better\n- Differentiable (for gradient descent)\n- Reflects the actual goal"
            },
            {
              "type": "text",
              "content": "## Common Loss Functions\n\n### Mean Squared Error (Regression)\n$$L = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n- Penalizes large errors heavily (squared)\n- Used for continuous outputs\n\n### Binary Cross-Entropy (Binary Classification)\n$$L = -\\frac{1}{n}\\sum[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})]$$\n- For 0/1 classification\n- Pairs with sigmoid activation\n\n### Categorical Cross-Entropy (Multi-class)\n$$L = -\\sum_{c=1}^{C} y_c \\log(\\hat{y}_c)$$\n- For multi-class classification\n- Pairs with softmax activation"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Loss Functions in Practice",
              "code": "import numpy as np\n\n# Mean Squared Error\ndef mse(y_true, y_pred):\n    return np.mean((y_true - y_pred)**2)\n\n# Binary Cross-Entropy\ndef binary_crossentropy(y_true, y_pred, eps=1e-15):\n    y_pred = np.clip(y_pred, eps, 1 - eps)  # Avoid log(0)\n    return -np.mean(y_true * np.log(y_pred) + \n                    (1 - y_true) * np.log(1 - y_pred))\n\n# Categorical Cross-Entropy\ndef categorical_crossentropy(y_true, y_pred, eps=1e-15):\n    y_pred = np.clip(y_pred, eps, 1 - eps)\n    return -np.sum(y_true * np.log(y_pred)) / len(y_true)\n\n# Examples\ny_true_reg = np.array([1.0, 2.0, 3.0])\ny_pred_reg = np.array([1.1, 2.2, 2.8])\nprint(f\"MSE: {mse(y_true_reg, y_pred_reg):.4f}\")\n\ny_true_bin = np.array([1, 0, 1, 1])\ny_pred_bin = np.array([0.9, 0.1, 0.8, 0.7])\nprint(f\"Binary CE: {binary_crossentropy(y_true_bin, y_pred_bin):.4f}\")"
            }
          ]
        },
        {
          "id": "gradient-descent",
          "title": "Gradient Descent Variants",
          "type": "lesson",
          "duration": "30 min",
          "authorCredits": {
            "keyContributors": ["Augustin-Louis Cauchy", "Herbert Robbins", "Sutton Monro"],
            "historicalNote": "Cauchy first described gradient descent in 1847. Robbins and Monro introduced stochastic gradient descent in 1951, enabling the scalable training of modern neural networks."
          },
          "content": [
            {
              "type": "text",
              "content": "## Vanilla Gradient Descent\n\n$$\\theta = \\theta - \\alpha \\nabla L(\\theta)$$\n\n**Problem:** Uses all data for each update (slow for large datasets)\n\n**The Learning Rate ($\\alpha$):**\n- Too high: Overshoots the minimum, may diverge\n- Too low: Very slow convergence\n- Just right: Converges efficiently to minimum"
            },
            {
              "type": "text",
              "content": "## Stochastic Gradient Descent (SGD)\n\nUpdate after each sample (or mini-batch):\n- Faster iterations\n- Noisy updates can escape local minima\n- More common in practice\n\n**Mini-batch SGD:** Update after small batch (e.g., 32 samples)\n- Balance between speed and stability"
            },
            {
              "type": "text",
              "content": "## SGD with Momentum\n\nAccumulate velocity from past gradients:\n\n$$v_t = \\beta v_{t-1} + \\nabla L(\\theta)$$\n$$\\theta = \\theta - \\alpha v_t$$\n\n**Benefits:**\n- Faster convergence\n- Dampens oscillations\n- Helps escape shallow local minima"
            },
            {
              "type": "code",
              "language": "python",
              "title": "SGD with Momentum",
              "code": "import numpy as np\n\nclass SGDMomentum:\n    def __init__(self, lr=0.01, momentum=0.9):\n        self.lr = lr\n        self.momentum = momentum\n        self.velocity = None\n    \n    def update(self, params, grads):\n        if self.velocity is None:\n            self.velocity = np.zeros_like(params)\n        \n        self.velocity = self.momentum * self.velocity + grads\n        params = params - self.lr * self.velocity\n        return params\n\n# Example optimization\ndef quadratic(x):\n    return x**2 + 10*np.sin(x)\n\ndef gradient(x):\n    return 2*x + 10*np.cos(x)\n\noptimizer = SGDMomentum(lr=0.1, momentum=0.9)\nx = 5.0\n\nfor i in range(50):\n    grad = gradient(x)\n    x = optimizer.update(x, grad)\n    if i % 10 == 0:\n        print(f\"Step {i}: x={x:.3f}, f(x)={quadratic(x):.3f}\")"
            },
            {
              "type": "text",
              "content": "## Common Gradient Problems\n\n### Local Minima and Saddle Points\nGradient descent can get stuck at:\n- **Local minima:** Points where gradient is zero but not the global best\n- **Saddle points:** Points that are minimum in one direction, maximum in another\n\n### Vanishing Gradients\nIn deep networks, gradients can become extremely small:\n- Happens with sigmoid/tanh activations\n- Early layers learn very slowly\n- **Solution:** Use ReLU, batch normalization, skip connections\n\n### Exploding Gradients\nGradients can grow exponentially large:\n- Common in recurrent networks (RNNs)\n- Causes unstable training, NaN values\n- **Solution:** Gradient clipping, careful initialization"
            }
          ]
        },
        {
          "id": "adam",
          "title": "Adam and Modern Optimizers",
          "type": "lesson",
          "duration": "30 min",
          "content": [
            {
              "type": "text",
              "content": "## Adam: Adaptive Moment Estimation\n\nAdam combines:\n1. **Momentum** (first moment)\n2. **RMSprop** (second moment - adaptive learning rates)\n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$$\n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$$\n$$\\theta = \\theta - \\alpha \\frac{m_t}{\\sqrt{v_t} + \\epsilon}$$\n\n**Default hyperparameters:**\n- $\\alpha = 0.001$\n- $\\beta_1 = 0.9$\n- $\\beta_2 = 0.999$\n- $\\epsilon = 10^{-8}$"
            },
            {
              "type": "text",
              "content": "## Why Adam is Popular\n\nâœ… Works well out-of-the-box\nâœ… Adapts learning rate per parameter\nâœ… Handles sparse gradients well\nâœ… Less sensitive to hyperparameters\n\n**Other modern optimizers:**\n- **AdamW:** Adam with weight decay (better regularization)\n- **LAMB:** Layerwise adaptive, good for large batch training\n- **Lion:** Newer optimizer from Google, memory efficient"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Using Optimizers in PyTorch",
              "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Simple model\nmodel = nn.Sequential(\n    nn.Linear(10, 32),\n    nn.ReLU(),\n    nn.Linear(32, 1)\n)\n\n# Different optimizers\noptimizers = {\n    'SGD': optim.SGD(model.parameters(), lr=0.01),\n    'SGD+Momentum': optim.SGD(model.parameters(), lr=0.01, momentum=0.9),\n    'Adam': optim.Adam(model.parameters(), lr=0.001),\n    'AdamW': optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01),\n}\n\n# Training loop skeleton\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\nfor epoch in range(100):\n    # Forward pass\n    X = torch.randn(32, 10)\n    y = torch.randn(32, 1)\n    pred = model(X)\n    loss = criterion(pred, y)\n    \n    # Backward pass\n    optimizer.zero_grad()  # Clear old gradients\n    loss.backward()        # Compute gradients\n    optimizer.step()       # Update weights\n    \n    if epoch % 20 == 0:\n        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")"
            }
          ]
        },
        {
          "id": "regularization",
          "title": "Regularization Techniques",
          "type": "lesson",
          "duration": "25 min",
          "content": [
            {
              "type": "text",
              "content": "## Why Regularization?\n\n**Overfitting:** Model memorizes training data but fails on new data.\n\n**Regularization:** Techniques to prevent overfitting by constraining the model."
            },
            {
              "type": "text",
              "content": "## L1 and L2 Regularization\n\nAdd penalty to loss function:\n\n**L2 (Ridge/Weight Decay):**\n$$L_{total} = L + \\lambda \\sum w_i^2$$\n- Pushes weights toward zero\n- Keeps all features, just shrinks them\n\n**L1 (Lasso):**\n$$L_{total} = L + \\lambda \\sum |w_i|$$\n- Creates sparse solutions (some weights = 0)\n- Feature selection effect"
            },
            {
              "type": "text",
              "content": "## Dropout\n\nRandomly set neurons to zero during training:\n$$h = h \\cdot \\text{mask}$$\n\nWhere mask is random 0s and 1s.\n\n**Why it works:**\n- Prevents co-adaptation\n- Ensemble effect (many sub-networks)\n- Implicit regularization"
            },
            {
              "type": "code",
              "language": "python",
              "title": "Regularization in Practice",
              "code": "import torch\nimport torch.nn as nn\n\nclass RegularizedNetwork(nn.Module):\n    def __init__(self, dropout_rate=0.5):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(784, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),  # Dropout!\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(128, 10)\n        )\n    \n    def forward(self, x):\n        return self.layers(x)\n\nmodel = RegularizedNetwork(dropout_rate=0.3)\n\n# L2 regularization via weight_decay\noptimizer = torch.optim.AdamW(\n    model.parameters(), \n    lr=0.001, \n    weight_decay=0.01  # L2 penalty\n)\n\nprint(\"Model with Dropout layers:\")\nprint(model)\n\n# Training vs Eval mode\nmodel.train()  # Dropout active\nmodel.eval()   # Dropout disabled"
            }
          ]
        },
        {
          "id": "numerical-stability",
          "title": "Numerical Stability in Practice",
          "type": "lesson",
          "duration": "25 min",
          "authorCredits": {
            "keyContributors": ["James Wilkinson"],
            "historicalNote": "James Wilkinson pioneered numerical stability analysis. His work on backward error analysis is why we know which algorithms work reliably with floating-point numbers."
          },
          "content": [
            {
              "type": "text",
              "content": "## Why Numerical Stability Matters\n\n**The Math Works. The Computer Doesn't.**\n\nComputers use finite precision floating-point numbers:\n- 32-bit float: ~7 decimal digits of precision\n- 64-bit double: ~16 decimal digits\n\n**When this breaks:**\n- Very large or small numbers\n- Subtracting nearly equal numbers\n- Summing many small numbers\n- Inverting ill-conditioned matrices"
            },
            {
              "type": "text",
              "content": "## Common Stability Problems in ML\n\n### 1. Log of Small Probabilities\n```python\n# BAD: Can produce -inf\nloss = np.log(probability)  # If probability â‰ˆ 0\n\n# GOOD: Add small epsilon\nloss = np.log(probability + 1e-10)\n# Or use log_softmax directly\n```\n\n### 2. Softmax Overflow\n```python\n# BAD: exp(1000) = inf\nsoftmax = np.exp(logits) / np.sum(np.exp(logits))\n\n# GOOD: Subtract max for stability\nlogits_stable = logits - np.max(logits)\nsoftmax = np.exp(logits_stable) / np.sum(np.exp(logits_stable))\n```\n\n### 3. Division by Zero\nAlways add epsilon to denominators!"
            },
            {
              "type": "text",
              "content": "## Never Invert Matrices Explicitly!\n\n**The Rule:** Don't compute $A^{-1}$. Solve the linear system instead.\n\n```python\n# BAD: Unstable and slow\nx = np.linalg.inv(A) @ b\n\n# GOOD: Use solve()\nx = np.linalg.solve(A, b)\n```\n\n**Why?**\n- Matrix inversion is O(nÂ³) and numerically unstable\n- `solve()` uses LU decomposition - more stable\n- For least squares, use `lstsq()` or SVD"
            },
            {
              "type": "text",
              "content": "## Condition Number: Predicting Trouble\n\nThe **condition number** measures how sensitive a matrix is to small changes:\n\n$$\\kappa(A) = \\|A\\| \\cdot \\|A^{-1}\\|$$\n\n| Condition Number | Stability |\n|-----------------|----------|\n| Îº â‰ˆ 1 | Well-conditioned |\n| Îº = 10â¶ | Losing 6 digits of precision |\n| Îº = 10Â¹â¶ | Results are meaningless (for double) |\n\n**Rule of thumb:** You lose logâ‚â‚€(Îº) decimal digits of precision."
            },
            {
              "type": "code",
              "language": "python",
              "title": "Numerical Stability Patterns",
              "code": "import numpy as np\n\n# 1. Stable softmax\ndef stable_softmax(x):\n    x_shifted = x - np.max(x)  # Subtract max for stability\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x)\n\nlogits = np.array([1000, 1001, 1002])  # Would overflow naive softmax\nprint(f\"Stable softmax: {stable_softmax(logits)}\")\n\n# 2. Log-sum-exp trick\ndef logsumexp(x):\n    c = np.max(x)\n    return c + np.log(np.sum(np.exp(x - c)))\n\nprint(f\"Log-sum-exp: {logsumexp(logits):.2f}\")\n\n# 3. Condition number\nA_good = np.array([[1, 0], [0, 1]])  # Identity\nA_bad = np.array([[1, 1], [1, 1.0001]])  # Nearly singular\n\nprint(f\"\\nCondition numbers:\")\nprint(f\"  Identity: {np.linalg.cond(A_good):.2f}\")\nprint(f\"  Ill-conditioned: {np.linalg.cond(A_bad):.2f}\")\n\n# 4. Solve vs inverse\nb = np.array([1, 2])\nx_inv = np.linalg.inv(A_good) @ b  # Works here, but avoid in general\nx_solve = np.linalg.solve(A_good, b)  # Always prefer this\nprint(f\"\\nSolve vs inverse match: {np.allclose(x_inv, x_solve)}\")"
            },
            {
              "type": "text",
              "content": "## Stability Checklist for ML\n\nâœ… Use `log_softmax` instead of `log(softmax(x))`\nâœ… Always add epsilon before dividing or logging\nâœ… Use `solve()` instead of `inv()`\nâœ… Use mixed precision carefully (fp16 can overflow)\nâœ… Check for NaN/Inf during training\nâœ… Initialize weights properly (avoid vanishing/exploding)\nâœ… Use gradient clipping for RNNs\n\n> *\"The purpose of computing is insight, not numbers.\"* â€” Richard Hamming"
            }
          ]
        },
        {
          "id": "optimization-quiz",
          "title": "Optimization Quiz",
          "type": "quiz",
          "duration": "10 min",
          "questions": [
            {
              "question": "What is the main advantage of Adam over vanilla SGD?",
              "options": [
                "Faster",
                "Adapts learning rate per parameter",
                "Uses less memory",
                "Simpler to implement"
              ],
              "correct": 1,
              "explanation": "Adam adapts the learning rate for each parameter individually using momentum and RMSprop."
            },
            {
              "question": "Which regularization technique can result in exactly zero weights?",
              "options": [
                "L2 (Ridge)",
                "L1 (Lasso)",
                "Dropout",
                "Batch Normalization"
              ],
              "correct": 1,
              "explanation": "L1 regularization produces sparse solutions where some weights become exactly zero."
            },
            {
              "question": "What does dropout do during training?",
              "options": [
                "Removes layers",
                "Randomly sets some neurons to zero",
                "Reduces learning rate",
                "Normalizes inputs"
              ],
              "correct": 1,
              "explanation": "Dropout randomly zeroes out a fraction of neurons during training to prevent overfitting."
            },
            {
              "question": "What advantage does Adam optimizer have over vanilla SGD?",
              "options": [
                "It uses no memory",
                "It adapts learning rates per parameter using momentum and RMSprop",
                "It guarantees finding the global minimum",
                "It works without gradients"
              ],
              "correct": 1,
              "explanation": "Adam combines momentum (first moment) and RMSprop (second moment) to adapt learning rates for each parameter, often leading to faster convergence."
            },
            {
              "question": "What is the vanishing gradient problem?",
              "options": [
                "Gradients become zero in the output layer",
                "Gradients become extremely small in early layers, stopping learning",
                "The model loses all its weights",
                "The GPU runs out of memory"
              ],
              "correct": 1,
              "explanation": "In deep networks with saturating activations (sigmoid/tanh), gradients can shrink exponentially as they backpropagate, making early layers learn very slowly."
            }
          ],
          "references": {
            "lessonRefs": [
              "loss-functions",
              "gradient-descent",
              "adam"
            ],
            "externalRefs": [
              {
                "title": "IBM: Gradient Descent",
                "url": "https://www.ibm.com/topics/gradient-descent"
              },
              {
                "title": "IBM: Neural Networks",
                "url": "https://www.ibm.com/topics/neural-networks"
              },
              {
                "title": "Distill Momentum",
                "url": "https://distill.pub/2017/momentum/"
              },
              {
                "title": "PyTorch Optimizers",
                "url": "https://pytorch.org/docs/stable/optim.html"
              }
            ]
          }
        }
      ]
    }
  ],
  "project": {
    "id": "math-capstone",
    "title": "Build a Neural Network from Scratch",
    "description": "Implement a complete neural network using only NumPy, applying all the math concepts learned.",
    "duration": "3 hours",
    "tasks": [
      "Implement matrix operations for forward pass",
      "Compute gradients using the chain rule",
      "Build gradient descent optimizer",
      "Add regularization",
      "Train on MNIST digits"
    ]
  }
}