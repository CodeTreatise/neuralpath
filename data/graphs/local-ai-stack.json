{
  "id": "local-ai-stack",
  "title": "Local AI Stack",
  "description": "Run AI completely on your own hardware - privacy, speed, no API costs",
  "sections": [
    { "id": "runtime", "title": "Inference & Runtime", "color": "#6366f1" },
    { "id": "models", "title": "Models & Hubs", "color": "#10b981" },
    { "id": "ui", "title": "UI & Apps", "color": "#f59e0b" },
    { "id": "hardware", "title": "Hardware", "color": "#ec4899" },
    { "id": "media", "title": "Media & RAG", "color": "#8b5cf6" }
  ],
  "nodes": [
    {"id": "local-ai", "label": "Local AI Stack", "type": "root", "section": "runtime", "description": "Run AI on your hardware", "difficulty": "Beginner"},
    
    {"id": "inference", "label": "Inference Engines", "type": "concept", "section": "runtime", "description": "Run models locally", "difficulty": "Intermediate"},
    {"id": "model-hubs", "label": "Model Sources", "type": "concept", "section": "models", "description": "Where to get models", "difficulty": "Beginner"},
    {"id": "ui-apps", "label": "UI Applications", "type": "concept", "section": "ui", "description": "User-friendly interfaces", "difficulty": "Beginner"},
    {"id": "hardware", "label": "Hardware", "type": "concept", "section": "hardware", "description": "What you need to run AI", "difficulty": "Beginner"},
    
    {"id": "local-llms", "label": "Local LLMs", "type": "concept", "section": "models", "description": "Language models to run", "difficulty": "Intermediate"},
    {"id": "local-image", "label": "Local Image Gen", "type": "concept", "section": "media", "description": "Run Stable Diffusion", "difficulty": "Intermediate"},
    {"id": "local-audio", "label": "Local Audio", "type": "concept", "section": "media", "description": "Speech & transcription", "difficulty": "Intermediate"},
    {"id": "local-rag", "label": "Local RAG", "type": "concept", "section": "media", "description": "Private document chat", "difficulty": "Advanced"},
    
    {"id": "ollama", "label": "Ollama", "type": "tool", "section": "runtime", "description": "Simplest way to run LLMs", "difficulty": "Beginner", "url": "https://ollama.com/"},
    {"id": "llamacpp", "label": "llama.cpp", "type": "tool", "section": "runtime", "description": "CPU-optimized inference", "difficulty": "Intermediate", "url": "https://github.com/ggerganov/llama.cpp"},
    {"id": "vllm", "label": "vLLM", "type": "tool", "section": "runtime", "description": "High-throughput GPU serving", "difficulty": "Advanced", "url": "https://docs.vllm.ai/"},
    {"id": "mlx", "label": "MLX", "type": "tool", "section": "runtime", "description": "Apple Silicon optimized", "difficulty": "Intermediate", "url": "https://github.com/ml-explore/mlx"},
    {"id": "exllama", "label": "ExLlamaV2", "type": "tool", "section": "runtime", "description": "Fast quantized inference", "difficulty": "Advanced", "url": "https://github.com/turboderp/exllamav2"},
    
    {"id": "huggingface", "label": "Hugging Face", "type": "tool", "section": "models", "description": "Largest model hub", "difficulty": "Beginner", "url": "https://huggingface.co/"},
    {"id": "ollama-lib", "label": "Ollama Library", "type": "tool", "section": "models", "description": "Curated, ready-to-run", "difficulty": "Beginner", "url": "https://ollama.com/library"},
    {"id": "gguf-models", "label": "GGUF Models", "type": "tool", "section": "models", "description": "Quantized for CPU", "difficulty": "Intermediate", "url": "https://huggingface.co/models?search=gguf"},
    {"id": "civitai", "label": "Civitai", "type": "tool", "section": "models", "description": "SD models & LoRAs", "difficulty": "Intermediate", "url": "https://civitai.com/"},
    
    {"id": "lmstudio", "label": "LM Studio", "type": "tool", "section": "ui", "description": "Beautiful chat UI", "difficulty": "Beginner", "url": "https://lmstudio.ai/"},
    {"id": "gpt4all", "label": "GPT4All", "type": "tool", "section": "ui", "description": "Privacy-focused chat", "difficulty": "Beginner", "url": "https://gpt4all.io/"},
    {"id": "jan", "label": "Jan", "type": "tool", "section": "ui", "description": "Open-source ChatGPT alt", "difficulty": "Beginner", "url": "https://jan.ai/"},
    {"id": "openwebui", "label": "Open WebUI", "type": "tool", "section": "ui", "description": "Self-hosted web interface", "difficulty": "Intermediate", "url": "https://docs.openwebui.com/"},
    
    {"id": "nvidia-gpu", "label": "NVIDIA GPU", "type": "tool", "section": "hardware", "description": "Best for AI inference", "difficulty": "Beginner"},
    {"id": "apple-silicon", "label": "Apple Silicon", "type": "tool", "section": "hardware", "description": "M1/M2/M3 unified memory", "difficulty": "Beginner"},
    {"id": "amd-gpu", "label": "AMD GPU", "type": "tool", "section": "hardware", "description": "ROCm support growing", "difficulty": "Advanced"},
    {"id": "cpu-only", "label": "CPU Only", "type": "tool", "section": "hardware", "description": "Slower but works", "difficulty": "Beginner"},
    
    {"id": "llama3", "label": "Llama 3", "type": "tool", "section": "models", "description": "Meta's latest (8B, 70B)", "difficulty": "Beginner", "url": "https://llama.meta.com/"},
    {"id": "mistral-local", "label": "Mistral", "type": "tool", "section": "models", "description": "Efficient 7B model", "difficulty": "Beginner", "url": "https://mistral.ai/"},
    {"id": "mixtral", "label": "Mixtral", "type": "tool", "section": "models", "description": "MoE 8x7B", "difficulty": "Intermediate", "url": "https://mistral.ai/news/mixtral-of-experts/"},
    {"id": "phi3", "label": "Phi-3", "type": "tool", "section": "models", "description": "Microsoft small model", "difficulty": "Beginner", "url": "https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-what-s-possible-with-slms/"},
    {"id": "qwen2", "label": "Qwen 2", "type": "tool", "section": "models", "description": "Alibaba's multilingual", "difficulty": "Intermediate", "url": "https://qwenlm.github.io/"},
    
    {"id": "automatic1111", "label": "AUTOMATIC1111", "type": "tool", "section": "media", "description": "Most popular SD UI", "difficulty": "Intermediate", "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui"},
    {"id": "comfyui", "label": "ComfyUI", "type": "tool", "section": "media", "description": "Node-based workflow", "difficulty": "Advanced", "url": "https://github.com/comfyanonymous/ComfyUI"},
    {"id": "fooocus", "label": "Fooocus", "type": "tool", "section": "media", "description": "Simple Midjourney-like", "difficulty": "Beginner", "url": "https://github.com/lllyasviel/Fooocus"},
    {"id": "sdnext", "label": "SD.Next", "type": "tool", "section": "media", "description": "A1111 fork, advanced", "difficulty": "Advanced", "url": "https://github.com/vladmandic/automatic"},
    
    {"id": "whisper-local", "label": "Whisper", "type": "tool", "section": "media", "description": "OpenAI speech-to-text", "difficulty": "Beginner", "url": "https://github.com/openai/whisper"},
    {"id": "whisperx", "label": "WhisperX", "type": "tool", "section": "media", "description": "Faster Whisper", "difficulty": "Intermediate", "url": "https://github.com/m-bain/whisperX"},
    {"id": "coqui-tts", "label": "Coqui TTS", "type": "tool", "section": "media", "description": "Voice synthesis", "difficulty": "Intermediate", "url": "https://github.com/coqui-ai/TTS"},
    {"id": "bark-local", "label": "Bark", "type": "tool", "section": "media", "description": "Suno's TTS model", "difficulty": "Intermediate", "url": "https://github.com/suno-ai/bark"},
    
    {"id": "privateGPT", "label": "PrivateGPT", "type": "tool", "section": "media", "description": "Chat with documents", "difficulty": "Intermediate", "url": "https://github.com/zylon-ai/private-gpt"},
    {"id": "localGPT", "label": "LocalGPT", "type": "tool", "section": "media", "description": "Document Q&A", "difficulty": "Intermediate", "url": "https://github.com/PromtEngineer/localGPT"},
    {"id": "khoj", "label": "Khoj", "type": "tool", "section": "media", "description": "Personal AI assistant", "difficulty": "Intermediate", "url": "https://khoj.dev/"},
    {"id": "memgpt", "label": "MemGPT", "type": "tool", "section": "media", "description": "Long-term memory", "difficulty": "Advanced", "url": "https://memgpt.ai/"}
  ],
  "links": [
    {"source": "local-ai", "target": "inference", "type": "category"},
    {"source": "local-ai", "target": "model-hubs", "type": "category"},
    {"source": "local-ai", "target": "ui-apps", "type": "category"},
    {"source": "local-ai", "target": "hardware", "type": "category"},
    
    {"source": "inference", "target": "ollama", "type": "instance"},
    {"source": "inference", "target": "llamacpp", "type": "instance"},
    {"source": "inference", "target": "vllm", "type": "instance"},
    {"source": "inference", "target": "mlx", "type": "instance"},
    {"source": "inference", "target": "exllama", "type": "instance"},
    
    {"source": "model-hubs", "target": "huggingface", "type": "instance"},
    {"source": "model-hubs", "target": "ollama-lib", "type": "instance"},
    {"source": "model-hubs", "target": "gguf-models", "type": "instance"},
    {"source": "model-hubs", "target": "civitai", "type": "instance"},
    
    {"source": "ui-apps", "target": "lmstudio", "type": "instance"},
    {"source": "ui-apps", "target": "gpt4all", "type": "instance"},
    {"source": "ui-apps", "target": "jan", "type": "instance"},
    {"source": "ui-apps", "target": "openwebui", "type": "instance"},
    
    {"source": "hardware", "target": "nvidia-gpu", "type": "instance"},
    {"source": "hardware", "target": "apple-silicon", "type": "instance"},
    {"source": "hardware", "target": "amd-gpu", "type": "instance"},
    {"source": "hardware", "target": "cpu-only", "type": "instance"},
    
    {"source": "local-ai", "target": "local-llms", "type": "category"},
    {"source": "local-ai", "target": "local-image", "type": "category"},
    {"source": "local-ai", "target": "local-audio", "type": "category"},
    {"source": "local-ai", "target": "local-rag", "type": "category"},
    
    {"source": "local-llms", "target": "llama3", "type": "instance"},
    {"source": "local-llms", "target": "mistral-local", "type": "instance"},
    {"source": "local-llms", "target": "mixtral", "type": "instance"},
    {"source": "local-llms", "target": "phi3", "type": "instance"},
    {"source": "local-llms", "target": "qwen2", "type": "instance"},
    
    {"source": "local-image", "target": "automatic1111", "type": "instance"},
    {"source": "local-image", "target": "comfyui", "type": "instance"},
    {"source": "local-image", "target": "fooocus", "type": "instance"},
    {"source": "local-image", "target": "sdnext", "type": "instance"},
    
    {"source": "local-audio", "target": "whisper-local", "type": "instance"},
    {"source": "local-audio", "target": "whisperx", "type": "instance"},
    {"source": "local-audio", "target": "coqui-tts", "type": "instance"},
    {"source": "local-audio", "target": "bark-local", "type": "instance"},
    
    {"source": "local-rag", "target": "privateGPT", "type": "instance"},
    {"source": "local-rag", "target": "localGPT", "type": "instance"},
    {"source": "local-rag", "target": "khoj", "type": "instance"},
    {"source": "local-rag", "target": "memgpt", "type": "instance"},
    
    {"source": "ollama", "target": "llama3", "type": "related", "label": "runs"},
    {"source": "ollama", "target": "openwebui", "type": "related", "label": "backend"},
    {"source": "lmstudio", "target": "gguf-models", "type": "related", "label": "uses"},
    {"source": "llamacpp", "target": "gguf-models", "type": "related", "label": "format"},
    {"source": "nvidia-gpu", "target": "vllm", "type": "related", "label": "required"},
    {"source": "apple-silicon", "target": "mlx", "type": "related", "label": "optimized"}
  ]
}
